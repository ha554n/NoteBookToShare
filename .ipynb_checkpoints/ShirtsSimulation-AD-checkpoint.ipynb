{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:15:41.533084Z",
     "start_time": "2020-10-05T22:15:41.528310Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# HTML('''<script>\n",
    "# code_show=true; \n",
    "# function code_toggle() {\n",
    "#  if (code_show){\n",
    "#  $('div.input').hide();\n",
    "#  } else {\n",
    "#  $('div.input').show();\n",
    "#  }\n",
    "#  code_show = !code_show\n",
    "# } \n",
    "# $( document ).ready(code_toggle);\n",
    "# </script>\n",
    "# <form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:15:44.469520Z",
     "start_time": "2020-10-05T22:15:41.539281Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "from math import pi\n",
    "from itertools import combinations_with_replacement\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.options.display.max_colwidth=100\n",
    "from natsort import natsorted\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats \n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import math as math\n",
    "import choix\n",
    "from astropy.stats import median_absolute_deviation\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:15:44.535305Z",
     "start_time": "2020-10-05T22:15:44.476475Z"
    }
   },
   "outputs": [],
   "source": [
    "def radarPlotDF(countsdf,maxpt,title,**kwargs):\n",
    "    \"\"\"\n",
    "    makes a radar plot from a dataframe with the first two columns being\n",
    "    used as 'pre' and 'post\n",
    "\n",
    "    countssdf: a 2 column dataframe with counts\n",
    "    maxpt: how to scale\n",
    "\n",
    "    optional-\n",
    "    colorcode: put color code or not? 'on' if yes.\n",
    "    \"\"\"\n",
    "    colorcode=kwargs.get('colorcode',None)\n",
    "    #set up colors\n",
    "    hues=np.linspace(0,1,16,endpoint=False)\n",
    "    hues=['%1.2f' % i for i in hues]\n",
    "    hues=[float(i) for i in hues]\n",
    "    colors = plt.cm.hsv(hues)\n",
    "    # Compute pie slices\n",
    "    N = 16\n",
    "    theta = np.linspace(0.0, 2 * np.pi, N, endpoint=False)\n",
    "    radii = np.repeat(1,N)\n",
    "    width = np.repeat(0.25,N)\n",
    "\n",
    "    #set up data\n",
    "    counts_df1=countsdf.iloc[:,0]\n",
    "    counts_df2=countsdf.iloc[:,1]\n",
    "    categories1=[str(i) for i in counts_df1.index]#cars\n",
    "    N = len(categories1)\n",
    "    #cars\n",
    "    values1=[i for i in counts_df1.values]\n",
    "    values1 += values1[:1] #makes it circular\n",
    "    values2=[i for i in counts_df2.values]\n",
    "    values2 += values2[:1] #makes it circular\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    #this doesn't change for all. all have 16 data points\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories1, color='grey', size=8)\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([i for i in np.arange(0,maxpt)],[],color=\"black\", size=5)\n",
    "    plt.ylim(0,maxpt)\n",
    "    # Plot data\n",
    "    ax.plot(angles, values1, linewidth=1, linestyle='solid')\n",
    "    ax.plot(angles, values2, linewidth=1, linestyle='solid')\n",
    "    # Fill area\n",
    "    ax.fill(angles, values1, 'b', alpha=0.1)\n",
    "    ax.fill(angles, values2, 'r', alpha=0.1)\n",
    "    if colorcode=='on':\n",
    "      bars = ax.bar(theta, radii, width=width, bottom=15, color=colors)\n",
    "    ax.legend(['Pre','Post'])\n",
    "    plt.title(title)\n",
    "    \n",
    "def interactiveRadar(countsDF,subname,category):\n",
    "    counts_df1=countsDF.iloc[:,0]#pre\n",
    "    counts_df2=countsDF.iloc[:,1]#post\n",
    "    counts_df3=countsDF.iloc[:,2]#pre\n",
    "    categories1=[str(i)[0:7] for i in counts_df1.index]#shirts\n",
    "    N = len(categories1)\n",
    "\n",
    "    values1=[i for i in counts_df1.values]\n",
    "    values1 += values1[:1] #makes it circular\n",
    "    values2=[i for i in counts_df2.values]\n",
    "    values2 += values2[:1] #makes it circular\n",
    "    values3=[i for i in counts_df3.values]\n",
    "    values3 += values3[:1] #makes it circular\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    #plot pre\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        opacity=0.75,\n",
    "          r=values1,\n",
    "          theta=categories1,\n",
    "          fill='toself',\n",
    "          name='Pre'\n",
    "    ))\n",
    "    #plot post\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        opacity=0.75,\n",
    "          r=values2,\n",
    "          theta=categories1,\n",
    "          fill='toself',\n",
    "          name='Post '\n",
    "    ))\n",
    "    #plot follow-up\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        opacity=0.75,\n",
    "        r=values3,\n",
    "        theta=categories1,\n",
    "        fill='toself',\n",
    "        name='3 Day '\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "    title=subname+' '+ category,\n",
    "      polar=dict(\n",
    "        radialaxis=dict(\n",
    "          visible=True,\n",
    "            showline=False,\n",
    "              range=[0, 16]\n",
    "        )),\n",
    "      showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def getPercentile(data):\n",
    "    p=[]\n",
    "    for q in [np.concatenate((np.arange(1,6,1),np.arange(95,100,1)))]:\n",
    "        p.append(np.percentile(data,q))\n",
    "        # print (\"{}%% percentile: {}\".format (q, np.percentile(randSim.aveAllMag, q)))\n",
    "    percentiles=pd.DataFrame(p,columns=q)\n",
    "    return(percentiles)\n",
    "def cdfTable(data,binz,spacing):\n",
    "    cdf=plt.hist(data,bins=np.arange(1,binz,spacing),density=True,cumulative=True)[0]\n",
    "    plt.close()\n",
    "    cdftable=pd.DataFrame(cdf,index=np.arange(1,binz-spacing,spacing))\n",
    "    return(cdftable.T)\n",
    "def mycdf(data):\n",
    "    data_size=len(data)\n",
    "    # Set bins edges\n",
    "    data_set=sorted(set(data))\n",
    "    bins=np.append(data_set, data_set[-1]+1)\n",
    "    # Use the histogram function to bin the data\n",
    "    counts, bin_edges = np.histogram(data, bins=bins, density=False)\n",
    "    counts=counts.astype(float)/data_size\n",
    "    # Find the cdf\n",
    "    cdf = np.cumsum(counts)\n",
    "    # Plot the cdf\n",
    "    plt.plot(bin_edges[0:-1], cdf,linestyle='--', marker=\"o\", color='b')\n",
    "    plt.ylim((0,1))\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.grid(True)\n",
    "  # plt.show()\n",
    "def colorcode(value):\n",
    "    \"\"\"\n",
    "    Colors elements in a dateframe\n",
    "    green if over 0.95\n",
    "    \"\"\"\n",
    "    ncomp=3\n",
    "    if value >= 1-(0.01/ncomp) or value <= (0.01/ncomp):\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    return 'color: %s' % color\n",
    "def getPscore(data,score):\n",
    "    pscore=stats.percentileofscore(data,score,kind='mean')\n",
    "    return(pscore/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:15:44.653003Z",
     "start_time": "2020-10-05T22:15:44.539257Z"
    }
   },
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
    "def score(df,stim,winner):\n",
    "    if winner==stim[0]: #if first of pair is winner\n",
    "        if np.isnan(df[stim[0]][stim[1]]):#if is nan\n",
    "            df[stim[0]][stim[1]]=1 #go to that coordinate and put 1 \n",
    "        else:\n",
    "            df[stim[0]][stim[1]]+=1#if not nan, then can add to it\n",
    "\n",
    "        if np.isnan(df[stim[1]][stim[0]]): #if symmetric pair is nan\n",
    "            df[stim[1]][stim[0]]=0 #go to symmetric coordinate and set to 0\n",
    "        else:\n",
    "            None\n",
    "            #keep it to where it is\n",
    "    if winner==stim[1]: #if first of pair is winner\n",
    "        if np.isnan(df[stim[1]][stim[0]]):#if is nan\n",
    "            df[stim[1]][stim[0]]=1 #go to that coordinate and put 1 \n",
    "        else:\n",
    "            df[stim[1]][stim[0]]+=1#if not nan, then can add to it\n",
    "\n",
    "        if np.isnan(df[stim[0]][stim[1]]): #if symmetric pair is nan\n",
    "            df[stim[0]][stim[1]]=0 #go to symmetric coordinate and set to 0\n",
    "        else:\n",
    "            None\n",
    "def MaxLikBT(M,n,npar):\n",
    "    Wi=np.sum(M).values#sum columns\n",
    "    par=np.ones([1,npar])/npar\n",
    "#     import pdb; pdb.set_trace()\n",
    "    for i in range(1000):\n",
    "        pi = np.ones([npar,1])*par;\n",
    "        pj = pi.T\n",
    "        par = Wi/np.sum(n/(pi+pj),axis=1)#sum columns, divide actual counts by it\n",
    "#         par=(par-np.min(par))/(np.max(par)-np.min(par))#minmax normalization    \n",
    "        par = par/np.sum(par)#normalize\n",
    "    return(par)\n",
    "def BTTest(par,npar):\n",
    "    \"\"\"\n",
    "    returnint transposed so p= pwin(col) over row\n",
    "    \"\"\"\n",
    "    M1=np.ones([npar,1])*par;#creates a 12x12 matrix from par, so now 12 rows of par which was 1x12\n",
    "    M2=M1.T\n",
    "    pij = M2/(M1+M2)\n",
    "    np.fill_diagonal(pij,0)\n",
    "    return(pij.T)\n",
    "def getPij(compMat,n,npar):\n",
    "    \"\"\"compMat is the matrix of competitions (1/0 for win or loss)\n",
    "    -n is number of comparisons\n",
    "    -npar is the number of parameters (shape of compMat)\n",
    "    \"\"\"\n",
    "    par=MaxLikBT(compMat,n,npar)\n",
    "    #par gives back\n",
    "    pij=BTTest(par,npar)\n",
    "    return(pij)\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "plotting\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def radarPlotDF(countsdf,maxpt,title,**kwargs):\n",
    "    \"\"\"\n",
    "    makes a radar plot from a dataframe with the first two columns being\n",
    "    used as 'pre' and 'post\n",
    "\n",
    "    countssdf: a 2 column dataframe with counts\n",
    "    maxpt: how to scale\n",
    "\n",
    "    optional-\n",
    "    colorcode: put color code or not? 'on' if yes.\n",
    "    \"\"\"\n",
    "    colorcode=kwargs.get('colorcode',None)\n",
    "    #set up colors\n",
    "#     hues=np.linspace(0,1,20,endpoint=False)\n",
    "#     hues=['%1.2f' % i for i in hues]\n",
    "#     hues=[float(i) for i in hues]\n",
    "#     colors = plt.cm.hsv(hues)\n",
    "#     colors=[[0.7137254901960784, 0.0, 0.0],\n",
    "#  [0.9254901960784314, 0.615686274509804, 0.0],\n",
    "#  [0.5411764705882353, 0.40784313725490196, 0.0],\n",
    "#  [1.0, 0.9607843137254902, 0.5215686274509804],\n",
    "#  [0.5725490196078431, 0.7215686274509804, 0.3254901960784314],\n",
    "#  [0.4627450980392157, 1.0, 0.0],\n",
    "#  [0.0, 0.5490196078431373, 0.0],\n",
    "#  [0.0, 0.2627450980392157, 0.00392156862745098],\n",
    "#  [0.0, 0.9529411764705882, 0.8],\n",
    "#  [0.0, 0.4823529411764706, 0.4117647058823529],\n",
    "#  [0.00392156862745098, 0.6470588235294118, 0.792156862745098],\n",
    "#  [0.6705882352941176, 0.8313725490196079, 1.0],\n",
    "#  [0.0, 0.0, 0.5607843137254902],\n",
    "#  [0.3803921568627451, 0.0, 0.6392156862745098],\n",
    "#  [0.7647058823529411, 0.30980392156862746, 1.0],\n",
    "#  [0.9294117647058824, 0.7176470588235294, 1.0],\n",
    "#  [0.5803921568627451, 0.0, 0.45098039215686275],\n",
    "#  [0.3607843137254902, 0.0, 0.06666666666666667],\n",
    "#  [0, 0, 0],\n",
    "#  [1, 1, 1]]\n",
    "\n",
    "    colors=[[0.7137254901960784, 0.0, 0.0],\n",
    " [0.9254901960784314, 0.615686274509804, 0.0],\n",
    " [0.5411764705882353, 0.40784313725490196, 0.0],\n",
    " [1.0, 0.9607843137254902, 0.5215686274509804],\n",
    " [0.5725490196078431, 0.7215686274509804, 0.3254901960784314],\n",
    " [0.4627450980392157, 1.0, 0.0],\n",
    " [0.0, 0.5490196078431373, 0.0],\n",
    " [0.0, 0.2627450980392157, 0.00392156862745098],\n",
    " [0.0, 0.9529411764705882, 0.8],\n",
    " [0.0, 0.4823529411764706, 0.4117647058823529],\n",
    " [0.00392156862745098, 0.6470588235294118, 0.792156862745098],\n",
    " [0.6705882352941176, 0.8313725490196079, 1.0],\n",
    " [0.0, 0.0, 0.5607843137254902],\n",
    " [0.3803921568627451, 0.0, 0.6392156862745098],\n",
    " [0.7647058823529411, 0.30980392156862746, 1.0],\n",
    " [0.9294117647058824, 0.7176470588235294, 1.0],\n",
    " [0.5803921568627451, 0.0, 0.45098039215686275],\n",
    " [0.3607843137254902, 0.0, 0.06666666666666667]]\n",
    "    \n",
    "    # Compute pie slices\n",
    "    N = 18\n",
    "    theta = np.linspace(0.0, 2 * np.pi, N, endpoint=False)\n",
    "    radii = np.repeat(1,N)\n",
    "    width = np.repeat(0.25,N)\n",
    "\n",
    "    #set up data\n",
    "    counts_df1=countsdf.iloc[:,0]\n",
    "    counts_df2=countsdf.iloc[:,1]\n",
    "    categories1=[str(i) for i in counts_df1.index]#cars\n",
    "    N = len(categories1)\n",
    "    #cars\n",
    "    values1=[i for i in counts_df1.values]\n",
    "    values1 += values1[:1] #makes it circular\n",
    "    values2=[i for i in counts_df2.values]\n",
    "    values2 += values2[:1] #makes it circular\n",
    "    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "    #this doesn't change for all. all have 16 data points\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "    # Initialise the spider plot\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    # Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], categories1, color='grey', size=8)\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    plt.yticks([i for i in np.arange(0,maxpt)],[],color=\"black\", size=5)\n",
    "    plt.ylim(0,maxpt)\n",
    "    # Plot data\n",
    "    ax.plot(angles, values1, linewidth=1, linestyle='solid')\n",
    "    ax.plot(angles, values2, linewidth=1, linestyle='solid')\n",
    "    # Fill area\n",
    "    ax.fill(angles, values1, 'b', alpha=0.1)\n",
    "    ax.fill(angles, values2, 'r', alpha=0.1)\n",
    "    if colorcode=='on':\n",
    "      bars = ax.bar(theta, radii, width=width, bottom=19, color=colors)\n",
    "    ax.legend(['Pre','Post'])\n",
    "    plt.title(title)\n",
    "    \n",
    "def interactiveRadar(countsDF,subname,category):\n",
    "    counts_df1=countsDF.iloc[:,0]#pre\n",
    "    counts_df2=countsDF.iloc[:,1]#post\n",
    "    counts_df3=countsDF.iloc[:,2]#fup\n",
    "    \n",
    "    categories1=[str(i)[0:7] for i in counts_df1.index]#shirts\n",
    "    N = len(categories1)\n",
    "\n",
    "    values1=[i for i in counts_df1.values]\n",
    "    values1 += values1[:1] #makes it circular\n",
    "    values2=[i for i in counts_df2.values]\n",
    "    values2 += values2[:1] #makes it circular\n",
    "    values3=[i for i in counts_df3.values]\n",
    "    values3 += values3[:1] #makes it circular\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    #plot pre\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        opacity=0.75,\n",
    "          r=values1,\n",
    "          theta=categories1,\n",
    "          fill='toself',\n",
    "          name='Pre'\n",
    "    ))\n",
    "    #plot post\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        opacity=0.75,\n",
    "          r=values2,\n",
    "          theta=categories1,\n",
    "          fill='toself',\n",
    "          name='Post '\n",
    "    ))\n",
    "    #plot follow-up\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        opacity=0.75,\n",
    "        r=values3,\n",
    "        theta=categories1,\n",
    "        fill='toself',\n",
    "        name='3 Day '\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "    title=subname+' '+ category,\n",
    "      polar=dict(\n",
    "        radialaxis=dict(\n",
    "          visible=True,\n",
    "            showline=False,\n",
    "              range=[0, len(countsDF)]\n",
    "        )),\n",
    "      showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "data tables\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "def getPercentile(data):\n",
    "    p=[]\n",
    "    for q in [np.concatenate((np.arange(1,6,1),np.arange(95,100,1)))]:\n",
    "        p.append(np.percentile(data,q))\n",
    "        # print (\"{}%% percentile: {}\".format (q, np.percentile(randSim.aveAllMag, q)))\n",
    "    percentiles=pd.DataFrame(p,columns=q)\n",
    "    return(percentiles)\n",
    "def cdfTable(data,binz,spacing):\n",
    "    cdf=plt.hist(data,bins=np.arange(1,binz,spacing),density=True,cumulative=True)[0]\n",
    "    plt.close()\n",
    "    cdftable=pd.DataFrame(cdf,index=np.arange(1,binz-spacing,spacing))\n",
    "    return(cdftable.T)\n",
    "def mycdf(data):\n",
    "    data_size=len(data)\n",
    "    # Set bins edges\n",
    "    data_set=sorted(set(data))\n",
    "    bins=np.append(data_set, data_set[-1]+1)\n",
    "    # Use the histogram function to bin the data\n",
    "    counts, bin_edges = np.histogram(data, bins=bins, density=False)\n",
    "    counts=counts.astype(float)/data_size\n",
    "    # Find the cdf\n",
    "    cdf = np.cumsum(counts)\n",
    "    # Plot the cdf\n",
    "    plt.plot(bin_edges[0:-1], cdf,linestyle='--', marker=\"o\", color='b')\n",
    "    plt.ylim((0,1))\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.grid(True)\n",
    "  # plt.show()\n",
    "def colorcode(value):\n",
    "    \"\"\"\n",
    "    Colors elements in a dateframe\n",
    "    green if over 0.95\n",
    "    \"\"\"\n",
    "    if value >= 0.9950 or value <= 0.005:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'black'\n",
    "    return 'color: %s' % color\n",
    "def getPscore(data,score):\n",
    "    pscore=stats.percentileofscore(data,score,kind='mean')\n",
    "    return(pscore/100)\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "esd\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "  #ESD\n",
    "def grubbs_stat(y):\n",
    "    \"\"\"\n",
    "    -max deviation is 2 sided!\n",
    "    -if multiple, picks the first one in the array\n",
    "    \"\"\"\n",
    "    std_dev = np.std(y)\n",
    "    avg_y = np.mean(y)\n",
    "    abs_val_minus_avg = abs(y - avg_y)\n",
    "    max_of_deviations = max(abs_val_minus_avg)\n",
    "    max_ind = np.argmax(abs_val_minus_avg)\n",
    "    Gcal = max_of_deviations/ std_dev\n",
    "#     print(\"Grubbs Statistics Value : {}\".format(Gcal))\n",
    "    return Gcal, max_ind\n",
    "def calculate_critical_value(size, alpha):\n",
    "    \"\"\"Calculate the critical value with the formula given for example in\n",
    "    https://en.wikipedia.org/wiki/Grubbs%27_test_for_outliers#Definition\n",
    "    Args:\n",
    "        ts (list or np.array): The timeseries to compute the critical value.\n",
    "        alpha (float): The significance level.\n",
    "    Returns:\n",
    "        float: The critical value for this test.\n",
    "    \"\"\"\n",
    "    t_dist = stats.t.ppf(1 - alpha / (2 * size), size - 2)\n",
    "    numerator = (size - 1) * np.sqrt(np.square(t_dist))\n",
    "    denominator = np.sqrt(size) * np.sqrt(size - 2 + np.square(t_dist))\n",
    "    critical_value = numerator / denominator\n",
    "#     print(\"Grubbs Critical Value: {}\".format(critical_value))\n",
    "    return critical_value\n",
    "def check_G_values(Gs, Gc, inp, max_index):\n",
    "    if Gs > Gc:\n",
    "        print('{} is an outlier. G > G-critical: {:.4f} > {:.4f} \\n'.format(inp[max_index], Gs, Gc))\n",
    "    else:\n",
    "        print('{} is not an outlier. G > G-critical: {:.4f} > {:.4f} \\n'.format(inp[max_index], Gs, Gc))\n",
    "def ESD_Test(input_series, alpha, max_outliers):\n",
    "    Gcritical_List=[]\n",
    "    max_index_List=[]\n",
    "    Gstat_List=[]\n",
    "    inputOrig=input_series.copy()\n",
    "    for iterations in range(max_outliers):\n",
    "        Gcritical = calculate_critical_value(len(input_series), alpha)\n",
    "        Gstat, max_index = grubbs_stat(input_series)\n",
    "#         check_G_values(Gstat, Gcritical, input_series, max_index)\n",
    "        input_series = np.delete(input_series, max_index)\n",
    "        \n",
    "        Gcritical_List.append(Gcritical)\n",
    "        max_index_List.append(max_index)\n",
    "        Gstat_List.append(Gstat)\n",
    "        \n",
    "    GDf=pd.DataFrame({'Gcritical':Gcritical_List,'max_val':[inputOrig[i] for i in max_index_List],'Gstat':Gstat_List})\n",
    "    GDf['outlier']=np.where(GDf.Gstat>GDf.Gcritical,1,0)\n",
    "    \n",
    "    outlsNZ=np.nonzero(GDf.outlier.values)[0]\n",
    "    t=[outlsNZ[i]==i for i in np.arange(len(outlsNZ))]\n",
    "    t2=[i for i, x in enumerate(t) if x]\n",
    "    tot=np.sum(list(GDf.outlier.values[t2]))\n",
    "    return(GDf,tot)\n",
    "\n",
    "\"\"\"\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "counts\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "def getPreLengths(countsdf):\n",
    "    '''\n",
    "    gets the indices where 'pre' is greater than 'post',npar is the number of items,competition df is a df of counts\n",
    "    pre and post\n",
    "    '''\n",
    "    npar=len(countsdf)\n",
    "    #IF >= MEANS COUNTS TIES (0) FOR BOTH STRINGS!\n",
    "    pre=np.where(countsdf.iloc[:,0]>=countsdf.iloc[:,1])[0]#indices where pre>post\n",
    "    addCircle=all(x in pre for x in [npar-1,0])#if any of the strings are at edges then have to make circular\n",
    "    prelist=[]\n",
    "    for k,g in groupby(enumerate(pre),lambda ix:ix[0]-ix[1]):\n",
    "        #this returns consecutive numbers. ex. if strings are [2,3,4,6,7,8,11,12]\n",
    "        #will return [[2,3,4],[6,7,8],[11,12]]\n",
    "        prelist.append(list(map(itemgetter(1),g)))\n",
    "    prelens=[len(i) for i in prelist]\n",
    "    if addCircle:#if strings at edges\n",
    "        #fix lengths\n",
    "        prelens[-1]=prelens[0]+prelens[-1]\n",
    "        prelens.pop(0)\n",
    "        #fix lists indices\n",
    "        lnf=[[item for sublist in [prelist[-1],prelist[0]] for item in sublist]]#join the last and first items\n",
    "        rest=prelist[1:-1]#get everyting except last and first\n",
    "        joined=[rest,lnf]# put together\n",
    "        prelist=[item for sublist in joined for item in sublist]\n",
    "    zeroIDX=np.where(countsdf.iloc[:,2]==0)[0]\n",
    "    for i in prelist:\n",
    "      for k in zeroIDX:\n",
    "        if k in i:\n",
    "          i.remove(k)\n",
    "    prelist=[x for x in prelist if x!=[]]\n",
    "    return(prelist)\n",
    "def getPostLengths(countsdf):\n",
    "    npar=len(countsdf)\n",
    "    #IF >= MEANS COUNTS TIES (0) FOR BOTH STRINGS!\n",
    "    post=np.where(countsdf.iloc[:,1]>=countsdf.iloc[:,0])[0]\n",
    "    addCircle=all(x in post for x in [npar-1,0])\n",
    "    postlist=[]\n",
    "    for k,g in groupby(enumerate(post),lambda ix:ix[0]-ix[1]):\n",
    "        postlist.append(list(map(itemgetter(1),g)))\n",
    "        #     print('string indices')\n",
    "        #     print(postlist)\n",
    "    postlens=[len(i) for i in postlist]\n",
    "    if addCircle:\n",
    "        postlens[-1]=postlens[0]+postlens[-1]\n",
    "        postlens.pop(0)\n",
    "        #fix lists indices\n",
    "        lnf=[[item for sublist in [postlist[-1],postlist[0]] for item in sublist]]#join the last and first items\n",
    "        rest=postlist[1:-1]#get everyting except last and first\n",
    "        joined=[rest,lnf]# put together\n",
    "        postlist=[item for sublist in joined for item in sublist]\n",
    "          #     print('string lengths')\n",
    "    zeroIDX=np.where(countsdf.iloc[:,2]==0)[0]\n",
    "    for i in postlist:\n",
    "      for k in zeroIDX:\n",
    "        if k in i:\n",
    "          i.remove(k)\n",
    "    postlist=[x for x in postlist if x!=[]]\n",
    "    return(postlist)\n",
    "\n",
    "def getCountsInfo(countsdf):\n",
    "    \"\"\"\n",
    "    combines count getter and does further computations on them.\n",
    "    \"\"\"\n",
    "    pre=countsdf.iloc[:,0].values\n",
    "    post=countsdf.iloc[:,1].values\n",
    "    #string Idx\n",
    "    preIdx=getPreLengths(countsdf)#get pre strings\n",
    "    postIdx=getPostLengths(countsdf)#get post strings\n",
    "\n",
    "    #flattened string idx\n",
    "    preFlat=[item for sublist in preIdx for item in sublist]\n",
    "    postFlat=[item for sublist in postIdx for item in sublist]\n",
    "    allFlat=preFlat+postFlat\n",
    "\n",
    "    #diff values\n",
    "    preDiff=np.abs(countsdf.iloc[:,2].iloc[preFlat].values)\n",
    "    postDiff=np.abs(countsdf.iloc[:,2].iloc[postFlat].values)\n",
    "    allDiff=np.abs(countsdf.iloc[:,2].iloc[allFlat].values)#CHANGE MADE was countsdf['DIFF'].values) so was counting zeros\n",
    "    allDiffz=np.abs(countsdf.iloc[:,2].values)\n",
    "\n",
    "    #length of each string\n",
    "    preLen=[len(i) for i in preIdx]\n",
    "    postLen=[len(i) for i in postIdx]\n",
    "    allLen=preLen+postLen\n",
    "\n",
    "    # of total strings\n",
    "    preNumStr=len(preLen)\n",
    "    postNumStr=len(postLen)\n",
    "    allNumStr=preNumStr+postNumStr\n",
    "\n",
    "    #average string length\n",
    "    avePreStrLen=np.sum(preLen)/preNumStr\n",
    "    avePostStrLen=np.sum(postLen)/postNumStr\n",
    "    aveAllStrLen=np.sum(allLen)/allNumStr\n",
    "\n",
    "    #sum of those individual strings\n",
    "    preSumStr=np.abs([np.sum(countsdf.iloc[:,2][i]) for i in preIdx])#sum of each string pre\n",
    "    postSumStr=np.abs([np.sum(countsdf.iloc[:,2][i]) for i in postIdx]) #sum of each string post\n",
    "    allSumStr=np.concatenate([[i for i in preSumStr],[i for i in postSumStr]])#combined sum of all strings\n",
    "\n",
    "    #overall sum of pre and post \n",
    "    preOverallStrSum=np.sum(preSumStr)\n",
    "    postOverallStrSum=np.sum(postSumStr)\n",
    "    allOverallStrSum=np.sum(allSumStr)\n",
    "\n",
    "    #average sum of a string pre/post\n",
    "    avePreStrSum=preOverallStrSum/preNumStr\n",
    "    avePostStrSum=postOverallStrSum/postNumStr\n",
    "    aveAllStrSum=allOverallStrSum/allNumStr\n",
    "\n",
    "    kD=choix.kendalltau_dist(pre,post)\n",
    "    \n",
    "    ESD=ESD_Test(allDiffz,0.05,3)[1]\n",
    "\n",
    "    outDF=pd.DataFrame([preNumStr,postNumStr,allNumStr,\n",
    "                      avePreStrLen,avePostStrLen,aveAllStrLen,\n",
    "                      preOverallStrSum,postOverallStrSum,allOverallStrSum,\n",
    "                      avePreStrSum,avePostStrSum,aveAllStrSum,\n",
    "                      preIdx,postIdx,\n",
    "                      preFlat,postFlat,allFlat,\n",
    "                      preLen,postLen,allLen,\n",
    "                      preDiff,postDiff,allDiff,allDiffz,\n",
    "                      preSumStr,postSumStr,allSumStr,pre,post,kD,ESD]).T\n",
    "    outDF.columns=(['preNumStr','postNumStr','allNumStr',\n",
    "                      'avePreStrLen','avePostStrLen','aveAllStrLen',\n",
    "                      'preOverallStrSum','postOverallStrSum','allOverallStrSum',\n",
    "                      'avePreStrSum','avePostStrSum','aveAllStrSum',\n",
    "                      'preIdx','postIdx',\n",
    "                      'preFlat','postFlat','allFlat',\n",
    "                      'preLen','postLen','allLen',\n",
    "                      'preDiff','postDiff','allDiff','allDiffz',\n",
    "                      'preSumStr','postSumStr','allSumStr','pre','post','kD','ESD'])\n",
    "    return(outDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All statistics are split into two categories, counts and ranks. The simulations were run with both ranks and counts. Counts statistics look solely at the number of wins, but do not consider the relative relationship of the counts within a list. The ranking method does. If there are ties, an average of the rank is given\n",
    "\n",
    "The true counts of each subject do show differences in the counts and ranks statistics, (except for kD, which is based on ranks for both anyway). These differences are not major and there is a correlation, but the differences can be seen from the radar plots as well. \n",
    "\n",
    "There are some differences in the overall outcomes of the tests in counts vs. ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**aveAllStrLen**: average length of the string. calculated as the overall length of pre and post strings divided by the total # of strings\n",
    "\n",
    "*    if no ties, total len must add to 16, so ranges from 16/2 =>8 to 16/16 =>1, anti-correlated with allNumStr. \n",
    "*     decreases with spikeyness\n",
    "\n",
    "**ESD**: uses the grubbs test sequentially to test for up to n number of outliers. here setting n=3,sig=0.05\n",
    "\n",
    "**kD**: distance metric derived from kendall to indicate dissimilarity or distance between two lists. proceeds by ranking and then computing number of rank order disagreements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.551Z"
    }
   },
   "outputs": [],
   "source": [
    "def getFinal(df):\n",
    "    \"\"\"\n",
    "    makes a final table of all statistics\n",
    "    \"\"\"\n",
    "    checkVal=1-(0.01/3)\n",
    "    subkeeper=[i for i in df.columns]\n",
    "    Results=pd.DataFrame({'Range':df.loc['aveAllStrLen'].gt(checkVal).values,\n",
    "                          'Outlier':df.loc['ESD'].gt(checkVal).values,\n",
    "#                           'Mixed':df.loc['allOverallStrSum'].gt(checkVal).values,\n",
    "                         'kD': df.loc['kD'].gt(checkVal).values},index=df.columns)\n",
    "#     return(Results)\n",
    "    Results['None']=[not(Results.loc[i].any()) for i in df.columns]\n",
    "    NoneKeeper=Results.index[Results['None']].values\n",
    "    [subkeeper.remove(i) for i in NoneKeeper]\n",
    "    RangeKeeper=Results.index[Results.Range]\n",
    "    [subkeeper.remove(i) for i in RangeKeeper]\n",
    "    OutlierKeeper=Results.index[Results.Outlier]\n",
    "    [subkeeper.remove(i) for i in OutlierKeeper]\n",
    "    kDKeeper=Results.index[Results.kD]\n",
    "#     [subkeeper.remove(i) for i in kDKeeper]\n",
    "    return(pd.DataFrame({'Range':[[int(re.findall(r'\\d+',i)[0]) for i in RangeKeeper]],\n",
    "                         'Outlier':[[int(re.findall(r'\\d+',i)[0]) for i in OutlierKeeper]],\n",
    "#                          'Mixed':[[int(re.findall(r'\\d+',i)[0]) for i in subkeeper]],\n",
    "                         'kD':[[int(re.findall(r'\\d+',i)[0]) for i in kDKeeper]],\n",
    "                         'None':[[int(re.findall(r'\\d+',i)[0]) for i in NoneKeeper]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load first visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.557Z"
    }
   },
   "outputs": [],
   "source": [
    "finalMatchSubs=['sub3','sub7','sub8','sub9','sub10','sub11','sub12','sub13','sub15','sub16','sub18','sub20',\n",
    " 'sub23','sub24','sub25','sub26','sub28','sub30','sub31','sub33','sub35','sub36','sub37','sub38',\n",
    " 'sub40','sub41','sub44','sub45','sub46','sub47','sub48','sub49','sub50','sub51','sub1','sub2','sub5','sub6','sub14','sub19','sub22','sub29','sub32','sub39','sub42']\n",
    "finalMatchSubs=natsorted(finalMatchSubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shirts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.564Z"
    }
   },
   "outputs": [],
   "source": [
    "checkList=['aveAllStrLen','ESD','kD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Counts - (Pre-Post) AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub1\n",
      "sub2\n",
      "sub3\n",
      "sub5\n",
      "sub6\n",
      "sub7\n",
      "sub8\n",
      "sub9\n",
      "sub10\n",
      "sub11\n",
      "sub12\n",
      "sub13\n",
      "sub14\n",
      "sub15\n",
      "sub16\n",
      "sub18\n",
      "sub19\n",
      "sub20\n",
      "sub22\n",
      "sub23\n",
      "sub24\n",
      "sub25\n",
      "sub26\n",
      "sub28\n",
      "sub29\n",
      "sub30\n",
      "sub31\n",
      "sub32\n",
      "sub33\n",
      "sub35\n"
     ]
    }
   ],
   "source": [
    "#subject clas for loading\n",
    "class Subject():\n",
    "    def __init__(self,subname):\n",
    "        self.subname=subname\n",
    "#load\n",
    "os.chdir(r\"C:\\Users\\al33m\\Box Sync\\Grzywacz Lab\\Experiment\\Data_Files\\scp\\Sim\\AD\\Shirts\")\n",
    "subs={}\n",
    "for i in finalMatchSubs:\n",
    "    print(i)\n",
    "    with open(i+'.pkl', 'rb') as input:\n",
    "        subs[i] = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Counts - (Pre-FollowUp) AC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.580Z"
    }
   },
   "outputs": [],
   "source": [
    "#make FUPsubs true counts\n",
    "AD_ShirtsTrueCounts=pd.DataFrame()\n",
    "for i in finalMatchSubs:\n",
    "    AD_ShirtsTrueCounts=AD_ShirtsTrueCounts.append(subs[i].AD_ShirtsTrueCounts)\n",
    "AD_ShirtsTrueCounts.index=finalMatchSubs\n",
    "AD_ShirtsTrueCounts[checkList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation - (Pre-FollowUp) AC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.587Z"
    }
   },
   "outputs": [],
   "source": [
    "AD_ShirtsCountTestDF=pd.DataFrame()\n",
    "for i in finalMatchSubs:\n",
    "  Pscore=[]\n",
    "  # print(i)\n",
    "  for measure in checkList:\n",
    "    # print(measure)\n",
    "    thisP=getPscore(getattr(subs[i],'AD_ShirtsCountsInfoSim')[measure],subs[i].AD_ShirtsTrueCounts[measure][0])\n",
    "    setattr(subs[i],'AD_Shirts_'+measure,thisP)\n",
    "    Pscore.append(thisP)\n",
    "  AD_ShirtsCountTestDF=AD_ShirtsCountTestDF.append(pd.DataFrame(Pscore).T)\n",
    "AD_ShirtsCountTestDF.columns=checkList\n",
    "AD_ShirtsCountTestDF.index=[i for i in subs.keys()]\n",
    "AD_ShirtsCountTestDF=AD_ShirtsCountTestDF.T\n",
    "AD_ShirtsCountTestDF.style.applymap(colorcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.592Z"
    }
   },
   "outputs": [],
   "source": [
    "AD_Shirts_Final=getFinal(AD_ShirtsCountTestDF)\n",
    "AD_Shirts_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.597Z"
    }
   },
   "outputs": [],
   "source": [
    "print('there are ' +str(len(AD_Shirts_Final.Range[0]))+ ' range out of 45')\n",
    "print('there are ' +str(len(AD_Shirts_Final.Outlier[0]))+ ' outlier out of 45')\n",
    "print('there are ' +str(len(AD_Shirts_Final.kD[0]))+ ' kD out of 45')\n",
    "print('there are ' +str(len(AD_Shirts_Final['None'][0]))+ ' None out of 45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.602Z"
    }
   },
   "outputs": [],
   "source": [
    "subs[i].ABCD_ShirtsCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.607Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in finalMatchSubs:\n",
    "    radarPlotDF(subs[i].ABCD_ShirtsCounts.iloc[:,np.r_[0,3]],15,i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-05T22:15:41.612Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.chdir(r\"C:\\Users\\al33m\\Box Sync\\Grzywacz Lab\\Experiment\\Data_Files\\scp\\Sim\\AC\\Shirts\")\n",
    "\n",
    "# for i in subs.keys() :\n",
    "#     print(i)\n",
    "#     with open(i+'.pkl', 'wb') as output:\n",
    "#         pickle.dump(subs[i],output, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
